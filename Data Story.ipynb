{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e85caa77",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64f7ea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.0/en_core_web_md-3.4.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 42.8 MB 542 kB/s eta 0:00:012\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from en-core-web-md==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.9.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (4.62.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (21.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.22.4)\n",
      "Requirement already satisfied: jinja2 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.26.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (8.1.1)\n",
      "Requirement already satisfied: setuptools in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (58.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.26.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (0.0.1)\n",
      "Requirement already satisfied: blis<0.10.0,>=0.7.8 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/shubhamladdha/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.4.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79693c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "# newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "# data = newsgroups_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6537ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "# data_words = list(sent_to_words(data[:4]))\n",
    "# print(data_words[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8637ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1caefe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d543b51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "544e0d0b",
   "metadata": {},
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723f6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/philosophy_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1030e5",
   "metadata": {},
   "source": [
    "+ The dataset contains over 300,000 sentences from over 50 texts spanning 10 major schools of philosophy. The represented schools are: Plato, Aristotle, Rationalism, Empiricism, German Idealism, Communism, Capitalism, Phenomenology, Continental Philosophy, and Analytic Philosophy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9441144",
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = ['plato', 'aristotle', 'empiricism', 'rationalism', 'analytic',\n",
    "           'continental', 'phenomenology', 'german_idealism', 'communism',\n",
    "           'capitalism', 'stoicism', 'nietzsche', 'feminism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b710fa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>school</th>\n",
       "      <th>sentence_spacy</th>\n",
       "      <th>sentence_str</th>\n",
       "      <th>original_publication_date</th>\n",
       "      <th>corpus_edition_date</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>sentence_lowered</th>\n",
       "      <th>tokenized_txt</th>\n",
       "      <th>lemmatized_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>125</td>\n",
       "      <td>what's new, socrates, to make you leave your ...</td>\n",
       "      <td>['what', 'new', 'socrates', 'to', 'make', 'you...</td>\n",
       "      <td>what be new , Socrates , to make -PRON- lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>69</td>\n",
       "      <td>surely you are not prosecuting anyone before t...</td>\n",
       "      <td>['surely', 'you', 'are', 'not', 'prosecuting',...</td>\n",
       "      <td>surely -PRON- be not prosecute anyone before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>74</td>\n",
       "      <td>the athenians do not call this a prosecution b...</td>\n",
       "      <td>['the', 'athenians', 'do', 'not', 'call', 'thi...</td>\n",
       "      <td>the Athenians do not call this a prosecution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>21</td>\n",
       "      <td>what is this you say?</td>\n",
       "      <td>['what', 'is', 'this', 'you', 'say']</td>\n",
       "      <td>what be this -PRON- say ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>101</td>\n",
       "      <td>someone must have indicted you, for you are no...</td>\n",
       "      <td>['someone', 'must', 'have', 'indicted', 'you',...</td>\n",
       "      <td>someone must have indict -PRON- , for -PRON- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360803</th>\n",
       "      <td>Women, Race, And Class</td>\n",
       "      <td>Davis</td>\n",
       "      <td>feminism</td>\n",
       "      <td>But the socialization of housework including m...</td>\n",
       "      <td>But the socialization of housework including m...</td>\n",
       "      <td>1981</td>\n",
       "      <td>1981</td>\n",
       "      <td>142</td>\n",
       "      <td>but the socialization of housework including m...</td>\n",
       "      <td>['but', 'the', 'socialization', 'of', 'housewo...</td>\n",
       "      <td>but the socialization of housework include me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360804</th>\n",
       "      <td>Women, Race, And Class</td>\n",
       "      <td>Davis</td>\n",
       "      <td>feminism</td>\n",
       "      <td>The only significant steps toward endingdomest...</td>\n",
       "      <td>The only significant steps toward endingdomest...</td>\n",
       "      <td>1981</td>\n",
       "      <td>1981</td>\n",
       "      <td>117</td>\n",
       "      <td>the only significant steps toward endingdomest...</td>\n",
       "      <td>['the', 'only', 'significant', 'steps', 'towar...</td>\n",
       "      <td>the only significant step toward endingdomest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360805</th>\n",
       "      <td>Women, Race, And Class</td>\n",
       "      <td>Davis</td>\n",
       "      <td>feminism</td>\n",
       "      <td>Working women, therefore, have a special and v...</td>\n",
       "      <td>Working women, therefore, have a special and v...</td>\n",
       "      <td>1981</td>\n",
       "      <td>1981</td>\n",
       "      <td>90</td>\n",
       "      <td>working women, therefore, have a special and v...</td>\n",
       "      <td>['working', 'women', 'therefore', 'have', 'spe...</td>\n",
       "      <td>working woman , therefore , have a special an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360806</th>\n",
       "      <td>Women, Race, And Class</td>\n",
       "      <td>Davis</td>\n",
       "      <td>feminism</td>\n",
       "      <td>Moreover, under capitalism, campaigns for jobs...</td>\n",
       "      <td>Moreover, under capitalism, campaigns for jobs...</td>\n",
       "      <td>1981</td>\n",
       "      <td>1981</td>\n",
       "      <td>199</td>\n",
       "      <td>moreover, under capitalism, campaigns for jobs...</td>\n",
       "      <td>['moreover', 'under', 'capitalism', 'campaigns...</td>\n",
       "      <td>moreover , under capitalism , campaign for jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360807</th>\n",
       "      <td>Women, Race, And Class</td>\n",
       "      <td>Davis</td>\n",
       "      <td>feminism</td>\n",
       "      <td>This strategy calls into question the validity...</td>\n",
       "      <td>This strategy calls into question the validity...</td>\n",
       "      <td>1981</td>\n",
       "      <td>1981</td>\n",
       "      <td>126</td>\n",
       "      <td>this strategy calls into question the validity...</td>\n",
       "      <td>['this', 'strategy', 'calls', 'into', 'questio...</td>\n",
       "      <td>this strategy call into question the validity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360808 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title author    school  \\\n",
       "0       Plato - Complete Works  Plato     plato   \n",
       "1       Plato - Complete Works  Plato     plato   \n",
       "2       Plato - Complete Works  Plato     plato   \n",
       "3       Plato - Complete Works  Plato     plato   \n",
       "4       Plato - Complete Works  Plato     plato   \n",
       "...                        ...    ...       ...   \n",
       "360803  Women, Race, And Class  Davis  feminism   \n",
       "360804  Women, Race, And Class  Davis  feminism   \n",
       "360805  Women, Race, And Class  Davis  feminism   \n",
       "360806  Women, Race, And Class  Davis  feminism   \n",
       "360807  Women, Race, And Class  Davis  feminism   \n",
       "\n",
       "                                           sentence_spacy  \\\n",
       "0        What's new, Socrates, to make you leave your ...   \n",
       "1       Surely you are not prosecuting anyone before t...   \n",
       "2       The Athenians do not call this a prosecution b...   \n",
       "3                                   What is this you say?   \n",
       "4       Someone must have indicted you, for you are no...   \n",
       "...                                                   ...   \n",
       "360803  But the socialization of housework including m...   \n",
       "360804  The only significant steps toward endingdomest...   \n",
       "360805  Working women, therefore, have a special and v...   \n",
       "360806  Moreover, under capitalism, campaigns for jobs...   \n",
       "360807  This strategy calls into question the validity...   \n",
       "\n",
       "                                             sentence_str  \\\n",
       "0        What's new, Socrates, to make you leave your ...   \n",
       "1       Surely you are not prosecuting anyone before t...   \n",
       "2       The Athenians do not call this a prosecution b...   \n",
       "3                                   What is this you say?   \n",
       "4       Someone must have indicted you, for you are no...   \n",
       "...                                                   ...   \n",
       "360803  But the socialization of housework including m...   \n",
       "360804  The only significant steps toward endingdomest...   \n",
       "360805  Working women, therefore, have a special and v...   \n",
       "360806  Moreover, under capitalism, campaigns for jobs...   \n",
       "360807  This strategy calls into question the validity...   \n",
       "\n",
       "        original_publication_date  corpus_edition_date  sentence_length  \\\n",
       "0                            -350                 1997              125   \n",
       "1                            -350                 1997               69   \n",
       "2                            -350                 1997               74   \n",
       "3                            -350                 1997               21   \n",
       "4                            -350                 1997              101   \n",
       "...                           ...                  ...              ...   \n",
       "360803                       1981                 1981              142   \n",
       "360804                       1981                 1981              117   \n",
       "360805                       1981                 1981               90   \n",
       "360806                       1981                 1981              199   \n",
       "360807                       1981                 1981              126   \n",
       "\n",
       "                                         sentence_lowered  \\\n",
       "0        what's new, socrates, to make you leave your ...   \n",
       "1       surely you are not prosecuting anyone before t...   \n",
       "2       the athenians do not call this a prosecution b...   \n",
       "3                                   what is this you say?   \n",
       "4       someone must have indicted you, for you are no...   \n",
       "...                                                   ...   \n",
       "360803  but the socialization of housework including m...   \n",
       "360804  the only significant steps toward endingdomest...   \n",
       "360805  working women, therefore, have a special and v...   \n",
       "360806  moreover, under capitalism, campaigns for jobs...   \n",
       "360807  this strategy calls into question the validity...   \n",
       "\n",
       "                                            tokenized_txt  \\\n",
       "0       ['what', 'new', 'socrates', 'to', 'make', 'you...   \n",
       "1       ['surely', 'you', 'are', 'not', 'prosecuting',...   \n",
       "2       ['the', 'athenians', 'do', 'not', 'call', 'thi...   \n",
       "3                    ['what', 'is', 'this', 'you', 'say']   \n",
       "4       ['someone', 'must', 'have', 'indicted', 'you',...   \n",
       "...                                                   ...   \n",
       "360803  ['but', 'the', 'socialization', 'of', 'housewo...   \n",
       "360804  ['the', 'only', 'significant', 'steps', 'towar...   \n",
       "360805  ['working', 'women', 'therefore', 'have', 'spe...   \n",
       "360806  ['moreover', 'under', 'capitalism', 'campaigns...   \n",
       "360807  ['this', 'strategy', 'calls', 'into', 'questio...   \n",
       "\n",
       "                                           lemmatized_str  \n",
       "0          what be new , Socrates , to make -PRON- lea...  \n",
       "1        surely -PRON- be not prosecute anyone before ...  \n",
       "2        the Athenians do not call this a prosecution ...  \n",
       "3                               what be this -PRON- say ?  \n",
       "4        someone must have indict -PRON- , for -PRON- ...  \n",
       "...                                                   ...  \n",
       "360803   but the socialization of housework include me...  \n",
       "360804   the only significant step toward endingdomest...  \n",
       "360805   working woman , therefore , have a special an...  \n",
       "360806   moreover , under capitalism , campaign for jo...  \n",
       "360807   this strategy call into question the validity...  \n",
       "\n",
       "[360808 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bc4f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['plato', 'aristotle', 'empiricism', 'rationalism', 'analytic',\n",
       "       'continental', 'phenomenology', 'german_idealism', 'communism',\n",
       "       'capitalism', 'stoicism', 'nietzsche', 'feminism'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct Schools\n",
    "df['school'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3dcef78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plato: ['Plato']\n",
      "aristotle: ['Aristotle']\n",
      "empiricism: ['Locke' 'Hume' 'Berkeley']\n",
      "rationalism: ['Spinoza' 'Leibniz' 'Descartes' 'Malebranche']\n",
      "analytic: ['Russell' 'Moore' 'Wittgenstein' 'Lewis' 'Quine' 'Popper' 'Kripke']\n",
      "continental: ['Foucault' 'Derrida' 'Deleuze']\n",
      "phenomenology: ['Merleau-Ponty' 'Husserl' 'Heidegger']\n",
      "german_idealism: ['Kant' 'Fichte' 'Hegel']\n",
      "communism: ['Marx' 'Lenin']\n",
      "capitalism: ['Smith' 'Ricardo' 'Keynes']\n",
      "stoicism: ['Epictetus' 'Marcus Aurelius']\n",
      "nietzsche: ['Nietzsche']\n",
      "feminism: ['Wollstonecraft' 'Beauvoir' 'Davis']\n"
     ]
    }
   ],
   "source": [
    "for sch in schools:\n",
    "    print(f'{sch}:', df[df['school']==sch]['author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b235e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plato: [-350]\n",
      "aristotle: [-320]\n",
      "empiricism: [1689 1739 1779 1713 1710]\n",
      "rationalism: [1677 1710 1637 1641 1674]\n",
      "analytic: [1921 1912 1910 1953 1985 1950 1959 1972 1975]\n",
      "continental: [1963 1961 1966 1967 1968 1972]\n",
      "phenomenology: [1945 1936 1907 1927 1950]\n",
      "german_idealism: [1788 1790 1781 1798 1817 1807 1820]\n",
      "communism: [1883 1848 1862]\n",
      "capitalism: [1776 1817 1936]\n",
      "stoicism: [125 170]\n",
      "nietzsche: [1888 1886 1887]\n",
      "feminism: [1792 1949 1981]\n"
     ]
    }
   ],
   "source": [
    "for sch in schools:\n",
    "    print(f'{sch}:',df[df['school']==sch]['original_publication_date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad092d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sch in schools:\n",
    "    print(f'{sch}:',df[df['school']==sch]['title'].unique())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fcec7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ['what', 'new', 'socrates', 'to', 'make', 'you...\n",
       "1         ['surely', 'you', 'are', 'not', 'prosecuting',...\n",
       "2         ['the', 'athenians', 'do', 'not', 'call', 'thi...\n",
       "3                      ['what', 'is', 'this', 'you', 'say']\n",
       "4         ['someone', 'must', 'have', 'indicted', 'you',...\n",
       "                                ...                        \n",
       "360803    ['but', 'the', 'socialization', 'of', 'housewo...\n",
       "360804    ['the', 'only', 'significant', 'steps', 'towar...\n",
       "360805    ['working', 'women', 'therefore', 'have', 'spe...\n",
       "360806    ['moreover', 'under', 'capitalism', 'campaigns...\n",
       "360807    ['this', 'strategy', 'calls', 'into', 'questio...\n",
       "Name: tokenized_txt, Length: 360808, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f57733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d87b62c2",
   "metadata": {},
   "source": [
    "### School: Capitalism & Author: Keynes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20df7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_ds = df[(df['school']=='capitalism') & (df['author']=='Keynes')]['tokenized_txt']\n",
    "data_words = []\n",
    "for key, value in truncated_ds.items():\n",
    "    value = ast.literal_eval(value)\n",
    "    data_words.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5585186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['capitalism', 'is', 'not', 'for', 'the', 'faint', 'of', 'heart'], ['it', 'is', 'system', 'of', 'supply', 'and', 'demand', 'that', 'reduces', 'real', 'workingmen', 'and', 'workingwomen', 'into', 'graphs', 'and', 'equations', 'subject', 'to', 'aggregate', 'observations', 'devoid', 'of', 'any', 'real', 'human', 'factors'], ['if', 'left', 'to', 'regulate', 'itself', 'the', 'economy', 'should', 'remain', 'in', 'check', 'and', 'avoid', 'dangerously', 'radical', 'changes', 'in', 'productivity', 'orthodox', 'economists', 'maintain'], ['how', 'then', 'do', 'we', 'explain', 'terrible', 'recessions', 'such', 'as', 'the', 'great', 'depression', 'where', 'unemployment', 'figures', 'were', 'seen', 'as', 'high', 'as', 'with', 'still', 'more', 'underemployed', 'and', 'working', 'far', 'below', 'their', 'experience', 'and', 'capability']]\n"
     ]
    }
   ],
   "source": [
    "print(data_words[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab91e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4799df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed652f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e15279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['system', 'corrected', 'dire', 'circumstances', 'created'], ['economists', 'reply', 'simply', 'workers', 'unwilling', 'accept', 'lower', 'wages', 'times', 'decline', 'would', 'rather', 'quit', 'thus', 'jeopardizing', 'beautifully', 'constructed', 'apparently', 'fragile', 'classical', 'theory', 'economics'], ['arguments', 'effective', 'always', 'fallback', 'plan', 'declaring', 'social', 'darwinism', 'great', 'depression', 'serving', 'perfect', 'opportunity', 'weed', 'worst', 'employees', 'best', 'would', 'emerge', 'victorious', 'unforeseeable', 'future', 'date'], ['first', 'months', 'following', 'explosion', 'depressed', 'economic', 'data', 'perhaps', 'population', 'would', 'nervously', 'accept', 'postulates']]\n"
     ]
    }
   ],
   "source": [
    "print(data_words_nostops[4:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6948e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efd0f0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['capitalism', 'faint', 'heart'], ['system', 'supply', 'demand', 'reduces', 'real', 'workingmen', 'workingwomen', 'graphs', 'equations', 'aggregate', 'observations', 'devoid', 'real', 'human', 'factors'], ['left', 'regulate', 'economy', 'remain', 'check', 'avoid', 'dangerously', 'radical', 'changes', 'productivity', 'orthodox', 'economists', 'maintain'], ['explain', 'terrible', 'recessions', 'great', 'depression', 'unemployment', 'figures', 'seen', 'high', 'still', 'underemployed', 'working', 'far', 'experience', 'capability']]\n"
     ]
    }
   ],
   "source": [
    "print(data_words_bigrams[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae0e438b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['economists', 'reply', 'simply', 'workers', 'unwilling', 'accept', 'lower', 'wages', 'times', 'decline', 'would', 'rather', 'quit', 'thus', 'jeopardizing', 'beautifully', 'constructed', 'apparently', 'fragile', 'classical', 'theory', 'economics']\n"
     ]
    }
   ],
   "source": [
    "print(bigram_mod[data_words_bigrams[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42dfb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "416a94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "621d8075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['capitalism', 'faint', 'heart'], ['system', 'supply', 'demand', 'reduce', 'real', 'workingmen', 'graph', 'equation', 'aggregate', 'observation', 'devoid', 'real', 'human', 'factor'], ['leave', 'regulate', 'economy', 'remain', 'check', 'avoid', 'dangerously', 'radical', 'change', 'productivity', 'orthodox', 'economist', 'maintain'], ['explain', 'terrible', 'recession', 'great', 'depression', 'unemployment', 'figure', 'see', 'high', 'still', 'underemploye', 'work', 'far', 'experience', 'capability']]\n"
     ]
    }
   ],
   "source": [
    "print(data_lemmatized[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a7790fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "texts = data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df789a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)], [(3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1)], [(16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)], [(29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "print(corpus[:4]) #it will print the corpus we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e54ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=20, random_state=100, \n",
    "                                            update_every=1, chunksize=100, passes=10, alpha='auto',\n",
    "                                            per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fd36a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.4954620e-05, 6.4954089e-05, 6.4954089e-05, ..., 6.4962129e-05,\n",
       "        6.4983193e-05, 6.4983193e-05],\n",
       "       [1.1823566e-04, 1.1823516e-04, 1.1823516e-04, ..., 1.1823519e-04,\n",
       "        1.1823517e-04, 1.1823517e-04],\n",
       "       [5.3729622e-05, 5.3727828e-05, 5.3727828e-05, ..., 5.3743533e-05,\n",
       "        5.3732667e-05, 5.3732667e-05],\n",
       "       ...,\n",
       "       [2.3122304e-05, 2.3121420e-05, 2.3121420e-05, ..., 2.3133098e-05,\n",
       "        2.3128347e-05, 2.3128347e-05],\n",
       "       [2.1653441e-05, 2.1651804e-05, 2.1651804e-05, ..., 2.1661515e-05,\n",
       "        2.1654796e-05, 2.1654796e-05],\n",
       "       [8.1381055e-05, 8.1380676e-05, 8.1380676e-05, ..., 8.1386570e-05,\n",
       "        8.1473947e-05, 8.1473947e-05]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29f01562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.266*\"time\" + 0.127*\"indeed\" + 0.073*\"conclusion\" + 0.073*\"standard\" + '\n",
      "  '0.062*\"analysis\" + 0.059*\"become\" + 0.055*\"profit\" + 0.012*\"derive\" + '\n",
      "  '0.000*\"increase\" + 0.000*\"investment\"'),\n",
      " (1,\n",
      "  '0.212*\"determine\" + 0.178*\"right\" + 0.054*\"other\" + 0.052*\"alternative\" + '\n",
      "  '0.006*\"third\" + 0.000*\"political\" + 0.000*\"wrong\" + 0.000*\"philosopher\" + '\n",
      "  '0.000*\"mood\" + 0.000*\"investment\"'),\n",
      " (2,\n",
      "  '0.153*\"term\" + 0.115*\"effect\" + 0.109*\"different\" + 0.107*\"policy\" + '\n",
      "  '0.048*\"short\" + 0.037*\"spend\" + 0.031*\"discussion\" + 0.028*\"economy\" + '\n",
      "  '0.027*\"government\" + 0.025*\"use\"'),\n",
      " (3,\n",
      "  '0.137*\"change\" + 0.092*\"level\" + 0.090*\"condition\" + 0.081*\"fall\" + '\n",
      "  '0.066*\"certain\" + 0.061*\"country\" + 0.058*\"proportion\" + 0.048*\"force\" + '\n",
      "  '0.044*\"assume\" + 0.036*\"show\"'),\n",
      " (4,\n",
      "  '0.288*\"interest\" + 0.251*\"rate\" + 0.077*\"price\" + 0.063*\"consumption\" + '\n",
      "  '0.034*\"part\" + 0.025*\"play\" + 0.020*\"book\" + 0.020*\"saving\" + '\n",
      "  '0.019*\"necessary\" + 0.019*\"dispute\"'),\n",
      " (5,\n",
      "  '0.409*\"wage\" + 0.096*\"however\" + 0.084*\"require\" + 0.080*\"market\" + '\n",
      "  '0.023*\"leave\" + 0.020*\"competition\" + 0.020*\"contract\" + 0.006*\"fair\" + '\n",
      "  '0.006*\"resist\" + 0.000*\"increase\"'),\n",
      " (6,\n",
      "  '0.276*\"economic\" + 0.123*\"system\" + 0.117*\"take\" + 0.083*\"hold\" + '\n",
      "  '0.058*\"particular\" + 0.044*\"rule\" + 0.030*\"never\" + 0.014*\"firm\" + '\n",
      "  '0.010*\"emphasise\" + 0.004*\"attractive\"'),\n",
      " (7,\n",
      "  '0.212*\"employment\" + 0.086*\"give\" + 0.075*\"output\" + 0.060*\"present\" + '\n",
      "  '0.051*\"depend\" + 0.048*\"result\" + 0.044*\"way\" + 0.043*\"whole\" + '\n",
      "  '0.043*\"future\" + 0.042*\"obvious\"'),\n",
      " (8,\n",
      "  '0.283*\"long\" + 0.101*\"latter\" + 0.020*\"chiefly\" + 0.000*\"investment\" + '\n",
      "  '0.000*\"increase\" + 0.000*\"trade\" + 0.000*\"period\" + 0.000*\"run\" + '\n",
      "  '0.000*\"capital\" + 0.000*\"balance\"'),\n",
      " (9,\n",
      "  '0.132*\"idea\" + 0.066*\"volume\" + 0.063*\"real\" + 0.062*\"demand\" + '\n",
      "  '0.060*\"factor\" + 0.052*\"aggregate\" + 0.051*\"write\" + 0.046*\"supply\" + '\n",
      "  '0.036*\"serve\" + 0.036*\"bring\"'),\n",
      " (10,\n",
      "  '0.269*\"even\" + 0.102*\"value\" + 0.078*\"event\" + 0.077*\"people\" + '\n",
      "  '0.074*\"contemporary\" + 0.058*\"receive\" + 0.044*\"least\" + 0.026*\"error\" + '\n",
      "  '0.023*\"put\" + 0.010*\"adjust\"'),\n",
      " (11,\n",
      "  '0.278*\"full\" + 0.134*\"low\" + 0.064*\"matter\" + 0.052*\"rather\" + '\n",
      "  '0.040*\"decline\" + 0.024*\"teach\" + 0.021*\"worker\" + 0.020*\"importance\" + '\n",
      "  '0.016*\"meet\" + 0.015*\"content\"'),\n",
      " (12,\n",
      "  '0.096*\"year\" + 0.092*\"much\" + 0.080*\"wealth\" + 0.077*\"rise\" + 0.069*\"man\" + '\n",
      "  '0.062*\"economist\" + 0.057*\"many\" + 0.051*\"power\" + 0.046*\"also\" + '\n",
      "  '0.044*\"think\"'),\n",
      " (13,\n",
      "  '0.181*\"point\" + 0.116*\"first\" + 0.108*\"case\" + 0.060*\"set\" + 0.045*\"little\" '\n",
      "  '+ 0.044*\"explanation\" + 0.043*\"view\" + 0.037*\"mind\" + 0.034*\"lie\" + '\n",
      "  '0.024*\"special\"'),\n",
      " (14,\n",
      "  '0.188*\"make\" + 0.131*\"less\" + 0.131*\"attempt\" + 0.085*\"commonly\" + '\n",
      "  '0.079*\"understand\" + 0.023*\"certainly\" + 0.023*\"wish\" + 0.022*\"worth\" + '\n",
      "  '0.003*\"index\" + 0.001*\"compile\"'),\n",
      " (15,\n",
      "  '0.113*\"practical\" + 0.110*\"course\" + 0.108*\"argument\" + 0.107*\"follow\" + '\n",
      "  '0.051*\"almost\" + 0.050*\"public\" + 0.042*\"opinion\" + 0.030*\"express\" + '\n",
      "  '0.028*\"continue\" + 0.024*\"hope\"'),\n",
      " (16,\n",
      "  '0.062*\"influence\" + 0.047*\"therefore\" + 0.043*\"field\" + 0.041*\"correct\" + '\n",
      "  '0.039*\"particularly\" + 0.038*\"answer\" + 0.036*\"perhaps\" + 0.035*\"possible\" '\n",
      "  '+ 0.033*\"day\" + 0.030*\"maintain\"'),\n",
      " (17,\n",
      "  '0.261*\"money\" + 0.122*\"theory\" + 0.093*\"quantity\" + 0.065*\"thus\" + '\n",
      "  '0.049*\"find\" + 0.037*\"lead\" + 0.031*\"classical\" + 0.025*\"general\" + '\n",
      "  '0.022*\"direction\" + 0.021*\"merely\"'),\n",
      " (18,\n",
      "  '0.080*\"state\" + 0.064*\"great\" + 0.064*\"production\" + 0.052*\"measure\" + '\n",
      "  '0.049*\"well\" + 0.043*\"exist\" + 0.041*\"work\" + 0.041*\"high\" + 0.038*\"place\" '\n",
      "  '+ 0.033*\"unemployment\"'),\n",
      " (19,\n",
      "  '0.316*\"new\" + 0.153*\"say\" + 0.088*\"expect\" + 0.039*\"quite\" + 0.037*\"belief\" '\n",
      "  '+ 0.022*\"principle\" + 0.002*\"shall_call\" + 0.000*\"investment\" + '\n",
      "  '0.000*\"current\" + 0.000*\"political\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8bc98b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>interest, rate, price, consumption, part, play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>idea, volume, real, demand, factor, aggregate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>influence, therefore, field, correct, particul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.4413</td>\n",
       "      <td>state, great, production, measure, well, exist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>influence, therefore, field, correct, particul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>full, low, matter, rather, decline, teach, wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2959</td>\n",
       "      <td>idea, volume, real, demand, factor, aggregate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.1858</td>\n",
       "      <td>idea, volume, real, demand, factor, aggregate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3236</td>\n",
       "      <td>even, value, event, people, contemporary, rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>state, great, production, measure, well, exist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>economic, system, take, hold, particular, rule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>interest, rate, price, consumption, part, play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>year, much, wealth, rise, man, economist, many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.2523</td>\n",
       "      <td>point, first, case, set, little, explanation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>money, theory, quantity, thus, find, lead, cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>wage, however, require, market, leave, competi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3033</td>\n",
       "      <td>term, effect, different, policy, short, spend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2498</td>\n",
       "      <td>influence, therefore, field, correct, particul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>term, effect, different, policy, short, spend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.1141</td>\n",
       "      <td>make, less, attempt, commonly, understand, cer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             0             4.0              0.1106   \n",
       "1             1             9.0              0.4118   \n",
       "2             2            16.0              0.2398   \n",
       "3             3            18.0              0.4413   \n",
       "4             4            16.0              0.1572   \n",
       "5             5            11.0              0.2183   \n",
       "6             6             9.0              0.2959   \n",
       "7             7             9.0              0.1858   \n",
       "8             8            10.0              0.3236   \n",
       "9             9            18.0              0.2936   \n",
       "10           10             6.0              0.1827   \n",
       "11           11             4.0              0.1106   \n",
       "12           12            12.0              0.2827   \n",
       "13           13            13.0              0.2523   \n",
       "14           14            17.0              0.1253   \n",
       "15           15             5.0              0.2740   \n",
       "16           16             2.0              0.3033   \n",
       "17           17            16.0              0.2498   \n",
       "18           18             2.0              0.3800   \n",
       "19           19            14.0              0.1141   \n",
       "\n",
       "                                             Keywords  \n",
       "0   interest, rate, price, consumption, part, play...  \n",
       "1   idea, volume, real, demand, factor, aggregate,...  \n",
       "2   influence, therefore, field, correct, particul...  \n",
       "3   state, great, production, measure, well, exist...  \n",
       "4   influence, therefore, field, correct, particul...  \n",
       "5   full, low, matter, rather, decline, teach, wor...  \n",
       "6   idea, volume, real, demand, factor, aggregate,...  \n",
       "7   idea, volume, real, demand, factor, aggregate,...  \n",
       "8   even, value, event, people, contemporary, rece...  \n",
       "9   state, great, production, measure, well, exist...  \n",
       "10  economic, system, take, hold, particular, rule...  \n",
       "11  interest, rate, price, consumption, part, play...  \n",
       "12  year, much, wealth, rise, man, economist, many...  \n",
       "13  point, first, case, set, little, explanation, ...  \n",
       "14  money, theory, quantity, thus, find, lead, cla...  \n",
       "15  wage, however, require, market, leave, competi...  \n",
       "16  term, effect, different, policy, short, spend,...  \n",
       "17  influence, therefore, field, correct, particul...  \n",
       "18  term, effect, different, policy, short, spend,...  \n",
       "19  make, less, attempt, commonly, understand, cer...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "    return sent_topics_df\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "#     contents = pd.Series(texts)\n",
    "#     sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "#     return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus)\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords']\n",
    "df_dominant_topic.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e2893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
